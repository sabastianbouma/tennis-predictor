{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "from sqlalchemy import create_engine\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE_PASSWORD = ''\n",
    "DATABASE_NAME = ''\n",
    "engine = create_engine('mysql+mysqlconnector://root:{password}@localhost:3306/{database}'.format(\n",
    "    password=DATABASE_PASSWORD,\n",
    "    database=DATABASE_NAME))\n",
    "connection = engine.connect()\n",
    "random.seed(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = 'https://www.tennisexplorer.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2000, 2022)[::-1]:\n",
    "    res = requests.get(BASE_URL+'calendar/atp-men/{year}/'.format(year=year))\n",
    "    soup_main = BeautifulSoup(res.content, \"html.parser\")\n",
    "    tournaments = soup_main.find(id=\"tournamentList\").find('tbody').find_all('tr',{'data-type':'main'})\n",
    "    nn=1\n",
    "    tot = len(tournaments)\n",
    "    for tournament in tournaments:\n",
    "        print('{}: tournament {}/{}'.format(year, nn,tot))\n",
    "        if len(tournament.findAll(class_='t-name'))>1:\n",
    "            n_players = int(tournament.find(class_='draw').text)\n",
    "            tournament_name = tournament.find('a')['href'].split('/')[1]\n",
    "            tournament_url = \"/{tournament_name}/{year}/atp-men/\".format(tournament_name=tournament_name, year=year)\n",
    "            res = requests.get(BASE_URL+tournament_url)\n",
    "            soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "            tournament_main = soup.find(id=\"center\")\n",
    "            results = tournament_main.find(class_='result')\n",
    "            tournament_info = tournament_main.find(class_='box boxBasic lGray').text\n",
    "\n",
    "            tournament_location = re.findall('(?<=\\()(\\w{1,})', tournament_main.find(class_=\"bg\").text)[0]\n",
    "            prizemoney = int(''.join(re.findall('\\d',tournament_info)))\n",
    "            prizemoney_currency = re.findall('\\d \\W',tournament_info)[0][-1]\n",
    "            court_surface = re.findall('[a-z]{1,}',tournament_info)[0]\n",
    "\n",
    "            tournament_data = [[year, tournament_name, tournament_location, court_surface, prizemoney, prizemoney_currency, n_players]]\n",
    "            print(tournament_data[0])\n",
    "            tournaments_df = pd.DataFrame(tournament_data, columns = ['Year','Tournament','Location','Surface','Prizemoney','Currency','Num_Players'])\n",
    "            tournaments_df.to_sql('tennis_tournaments',con=connection, if_exists='append',index=False)\n",
    "            print('tournament_db updated')\n",
    "            seeds = [\n",
    "                [\n",
    "                    player.find('a')['href'],\n",
    "                    int(re.findall('(?<=\\()(\\d{1,})', player.text)[0])\n",
    "                ]\n",
    "                for player in results.findAll(class_='t-name')\n",
    "                if len(re.findall('(?<=\\()(\\d{1,})', player.text))>0\n",
    "            ]\n",
    "            seeds_df = pd.DataFrame(seeds, columns=['Player_ID','Seed'])\n",
    "            seeds_df.drop_duplicates(inplace=True)\n",
    "            seeds_df['Tournament'] = tournament_name\n",
    "            seeds_df['Year'] = year\n",
    "            seeds_df.to_sql('tennis_seeds',con=connection, index=False, if_exists='append')\n",
    "            print('seeds_db updated')\n",
    "            n_games = int(len(results.find('tbody').findAll('tr', {'id':True}))/2)\n",
    "            rounds = []\n",
    "            for i in range(int(np.log2(n_games))+1):\n",
    "                rounds+=[i]*(2**i)\n",
    "            rounds = rounds[:n_games]\n",
    "\n",
    "            player_urls = [i.find('a')['href'] for i in results.findAll(class_=\"t-name\")]\n",
    "\n",
    "            match_dates = []\n",
    "            tournament_ids = [tournament_name]*n_games\n",
    "            match_ids = range(n_games)\n",
    "            match_played_ids = [i//2 for i in range(n_games*2)]\n",
    "            match_results = []\n",
    "            sets_won = []\n",
    "            set_1s = []\n",
    "            set_2s = []\n",
    "            set_3s = []\n",
    "            set_4s = []\n",
    "            set_5s = []\n",
    "            for i in range(n_games):\n",
    "                id=i\n",
    "                single_score = results.find(id='r{}'.format(id))\n",
    "                date_text = single_score.find(class_='first time').text.split('.')\n",
    "                match_dates.append(datetime.datetime(year, int(date_text[1]),int(date_text[0])))\n",
    "                scores = single_score.findAll(class_='score')\n",
    "                s1, s2, s3, s4, s5 = [i.text[0] for i in scores]+[None]*(5-len(scores))\n",
    "                match_results.append(1)\n",
    "                set_1s.append(s1)\n",
    "                set_2s.append(s2)\n",
    "                set_3s.append(s3)\n",
    "                set_4s.append(s4)\n",
    "                set_5s.append(s5)\n",
    "                sets_won.append(single_score.find(class_='result').text)\n",
    "\n",
    "\n",
    "                single_score = results.find(id='r{}b'.format(id))\n",
    "                scores = single_score.findAll(class_='score')\n",
    "                s1, s2, s3, s4, s5 = [i.text[0] for i in scores]+[None]*(5-len(scores))\n",
    "                match_results.append(0)\n",
    "                set_1s.append(s1)\n",
    "                set_2s.append(s2)\n",
    "                set_3s.append(s3)\n",
    "                set_4s.append(s4)\n",
    "                set_5s.append(s5)\n",
    "                sets_won.append(single_score.find(class_='result').text)\n",
    "\n",
    "            matches_dict = {\n",
    "                'Tournament_ID':tournament_ids,\n",
    "                'Round':rounds,\n",
    "                'Date':match_dates,\n",
    "                'Match_ID':match_ids\n",
    "            }\n",
    "            matches_df = pd.DataFrame(matches_dict)\n",
    "            matches_df.to_sql('tennis_matches',con=connection, index=False, if_exists='append')\n",
    "            print('matches_db updated')\n",
    "\n",
    "            match_played_dict = {\n",
    "                'Tournament_ID':[tournament_name]*n_games*2,\n",
    "                'Year':[year]*n_games*2,\n",
    "                'Match_ID':match_played_ids,\n",
    "                'Player_ID':player_urls,\n",
    "                'Result':match_results,\n",
    "                'Sets Won': sets_won,\n",
    "                'Set 1': set_1s,\n",
    "                'Set 2': set_2s,\n",
    "                'Set 3': set_3s,\n",
    "                'Set 4': set_4s,\n",
    "                'Set 5': set_5s,\n",
    "            }\n",
    "            match_played_df = pd.DataFrame(match_played_dict)\n",
    "            match_played_df.to_sql('tennis_match_played',con=connection, index=False, if_exists='append')\n",
    "            print('match_played_db updated')\n",
    "\n",
    "            unique_urls = match_played_df['Player_ID'].unique()\n",
    "            player_data = []\n",
    "            try:\n",
    "                res = connection.execute(\"\"\"\n",
    "                SELECT\n",
    "                    URL\n",
    "                FROM\n",
    "                    tennis_players\n",
    "                \"\"\").fetchall()\n",
    "                existing_urls = [str(i[0]) for i in res]\n",
    "            except:\n",
    "                existing_urls = []\n",
    "            all_urls = list(set(unique_urls).difference(existing_urls))\n",
    "            for player_url in all_urls:\n",
    "                res = requests.get(BASE_URL+player_url)\n",
    "                soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "                player = soup.find(id=\"center\")\n",
    "                info = player.findAll(class_=\"date\")\n",
    "                name = re.findall('([\\w\\s]*) - Tennis Explorer', soup.title.text)[0]\n",
    "                text = str([i.text for i in info])\n",
    "                country = re.findall('(?<=Country: )(\\w*)', text)\n",
    "                height = re.findall('(?<=Height \\/ Weight: )(\\d{1,})', text)\n",
    "                weight = re.findall('(?<=cm \\/ )(\\d{1,})', text)\n",
    "                try:\n",
    "                    dates = re.findall('(?<=Age: \\d{2} \\()(\\d{1,2}). (\\d{1,2}). (\\d{4})', text)[0]\n",
    "                    date = datetime.datetime(int(dates[2]), int(dates[1]), int(dates[0])).date()\n",
    "                except:\n",
    "                    date=-1\n",
    "                plays = re.findall('(?<=Plays: )(\\w*)', text)\n",
    "                data_i = [player_url, name, country, date, height, weight, plays]\n",
    "                for i in range(len(data_i)):\n",
    "                    data_i_single = data_i[i]\n",
    "                    if type(data_i_single)==list:\n",
    "                        if len(data_i_single)==0:\n",
    "                            data_i[i] = -1\n",
    "                        else:\n",
    "                            data_i[i] = data_i_single[0]\n",
    "                player_data.append(data_i)\n",
    "\n",
    "            players_df = pd.DataFrame(player_data, columns = ['URL','Name','Nationality','DOB','Height','Weight','Handedness'])\n",
    "\n",
    "            players_df.to_sql('tennis_players',con=connection, index=False, if_exists='append')\n",
    "            print('players_db updated')\n",
    "        nn+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0d1e997bfa4e8a21f71bb42567cb5e702d28b7a563c5cbd58154ee73a197b8c9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
